{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZjBX5amSvSLo"},"outputs":[],"source":["\"\"\"\n","# Tumor(Breast) Image Classification Using CNN\n","\"\"\"\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","\"\"\"\n","# Data Import\n","# Import basic libraries\n","\"\"\"\n","\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import os \n","import pathlib \n","import random\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import Sequential\n","from tensorflow.keras.utils import image_dataset_from_directory\n","from tensorflow.keras import layers "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"N3wPcpTHwuD8"},"outputs":[],"source":["%cd /content/drive/MyDrive/Github/\n","%cd TumorDetect\n","%ls -al"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9AAJBvPxoVU"},"outputs":[],"source":["\"\"\"\n","# Path and class names\n","\"\"\"\n","\n","path = '/content/drive/MyDrive/Github/TumorDetect/Images'\n","data_dir = pathlib.Path(path)\n","\n","class_names = np.array([item.name for item in data_dir.glob(\"*\")])\n","class_names\n","\n","\"\"\"\n","# Image count\n","\"\"\"\n","\n","benignPath = pathlib.Path(os.path.join(data_dir,'benign'))\n","normalPath = pathlib.Path(os.path.join(data_dir,'normal'))\n","malignantPath = pathlib.Path(os.path.join(data_dir,'malignant'))\n","\n","benignImageCount = len(list(benignPath.glob('*.png')))\n","malignantImageCount = len(list(malignantPath.glob('*.png')))\n","normalImageCount = len(list(normalPath.glob('*.png')))\n","totalImageCount = benignImageCount + malignantImageCount + normalImageCount\n","\n","print(\"Total Images: \", totalImageCount)\n","print(\"Benign (non-dangerous) Images: {}({})\".format(benignImageCount, round(benignImageCount*100/totalImageCount, 2)))\n","print(\"Malignant (dangerous) Images: {}({})\".format(malignantImageCount, round(malignantImageCount*100/totalImageCount, 2)))\n","print(\"Normal (No Traces) Images: {}({})\".format(normalImageCount, round(normalImageCount*100/totalImageCount, 2)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-VgbfvyRyLy4"},"outputs":[],"source":["\"\"\"\n","# CNN\n","\"\"\"\n","\n","batch_size = 32\n","img_height = 224\n","img_width = 224\n","\n","\"\"\"\n","# Separating data sets\n","\"\"\"\n","\n","\n","train_data = image_dataset_from_directory(data_dir,validation_split=0.2,subset=\"training\",seed=123,image_size=(img_height, img_width),batch_size=batch_size)\n","\n","val_data = image_dataset_from_directory(data_dir,validation_split=0.2,subset=\"validation\",seed=123,image_size=(img_height,img_width),batch_size=batch_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4e59OyFAymvI"},"outputs":[],"source":["\"\"\"\n","# Define Model\n","# Rescale images add a Dropout to avoid the overfitting\n","# Softmax as activation for dense layer, Relu for conv layers\n","# 7 layer CNN Model Architecture with 3 Convolution layer each followed by max pooling layer\n","# Filter size =3X3 and Activation function = Relu\n","\"\"\"\n","\n","model = tf.keras.Sequential([\n","  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n","    \n","  layers.Conv2D(16, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","    \n","  layers.Conv2D(32, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","    \n","  layers.Conv2D(64, 3, padding='same', activation='relu'),\n","  layers.MaxPooling2D(),\n","    \n","  layers.Dropout(0.5),\n","  layers.Flatten(),\n","  layers.Dense(128, activation='relu'),\n","  layers.Dense(3,activation=\"softmax\")\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6tnM7ynZyrcW"},"outputs":[],"source":["\"\"\"\n","# Compile and fit the Model\n","\"\"\"\n","\n","model.compile(optimizer=\"Adam\",\n","            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","            metrics=[\"accuracy\"])\n","\n","epochs = 2\n","history = model.fit(train_data,\n","                    epochs=epochs,\n","                    validation_data=val_data, \n","                    batch_size=batch_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vgj4o_VA0C49"},"outputs":[],"source":["\"\"\"\n","# History Keys\n","\"\"\"\n","\n","history.history.keys()\n","\n","\"\"\"# Accuracy vs Lost\"\"\"\n","\n","acc = history.history['accuracy']\n","val_acc =  history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8,8))\n","plt.subplot(1,2,1)\n","plt.plot(epochs_range,acc,label='Accuracy')\n","plt.plot(epochs_range,val_acc,label=\"Validation Accuracy\")\n","plt.legend()\n","\n","plt.subplot(1,2,2)\n","plt.plot(epochs_range,loss,label='Loss')\n","plt.plot(epochs_range,val_loss,label=\"Validation Loss\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jHrRdB0j0JKE"},"outputs":[],"source":["\"\"\"\n","# Model Evaluation returns loss and accuracy\n","\"\"\"\n","\n","model.evaluate(val_data)\n","\n","\"\"\"\n","# Model summary\n","\"\"\"\n","\n","model.summary()\n","\n","\"\"\"\n","# Test Model\n","\"\"\"\n","\n","plt.figure(figsize=(15, 15))\n","class_names = val_data.class_names\n","result = ' | False'\n","for images, labels in val_data.take(1):\n","    for i in range(25):\n","        \n","        ax = plt.subplot(5, 5, i + 1)\n","        img = images[i].numpy().astype(\"uint8\")\n","        img = tf.expand_dims(img, axis=0)\n","        \n","        predictions = model.predict(img)\n","        predicted_class = np.argmax(predictions)\n","        if class_names[predicted_class] == class_names[labels[i]]:\n","            result = ' | TRUE'\n","            \n","        plt.imshow(images[i].numpy().astype(\"uint8\"))\n","        plt.title(class_names[predicted_class]+result)\n","        plt.axis(\"off\")"]}],"metadata":{"colab":{"provenance":[{"file_id":"1g7_pcCxs_GXSkxe4vwBbjNzxHD_FuQUu","timestamp":1680267367918}],"authorship_tag":"ABX9TyPb8g6R3R1rUvBAjy8o+w+X"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}